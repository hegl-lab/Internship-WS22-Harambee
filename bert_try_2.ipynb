{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea05dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_confustion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertConfig, BertPreTrainedModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2060a7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58984, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2data = r\"C:\\Users\\samer\\Documents\\university\\anf√§nger_praktikum\\harambee\\ej_formal_shareable.csv\"\n",
    "df = pd.read_csv(path2data)\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df = df[df[\"job_category\"].isin([\"Unclassified\"]) == False]\n",
    "df['job_title'] = df.job_title.apply(lambda x: str.lower(x))\n",
    "bag_of_word_to_remove = ['gsa', 'gsa ','deli ', 'ict ', '2020 ', 'none ', 'none', 'p40', 'p40 ', 'ecd', 'ict']\n",
    "df = df[df['job_title'].isin(bag_of_word_to_remove) == False]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e72183",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.22.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-cased')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6e873da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing MyModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing MyModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['linear.weight', 'linear.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "HIDDEN_SIZE_BERT = 768\n",
    "EMBED_SIZE_WORD = 128\n",
    "\n",
    "class MyModel(BertPreTrainedModel):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        \"\"\" Using Bert, define custom Model. \n",
    "        [*]: check important parts. \"\"\"\n",
    "        super(MyModel, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        \n",
    "        # recursively load into the BERT submodule the first time you call pre-trained weights. [*]\n",
    "        self.init_weights()\n",
    "        \n",
    "        # customized layer - these layers' wieghts are not initialized.\n",
    "        self.linear = nn.Linear(kwargs['hidden_size_bert'], kwargs['embed_size_word'])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        \"\"\" forward step of BERT and pass customed layers.\n",
    "        input_ids: prerequesite: \"\"\"\n",
    "        # pdb.set_trace() # debugging\n",
    "        #hiddens, pooled, hiddens_all\n",
    "        output = self.bert(input_ids, \n",
    "                            attention_mask=attention_mask\n",
    "                            ) #token_type_ids=token_type_ids\n",
    "        out = self.linear(output[0])\n",
    "        return out#out, hiddens, hiddens_all # [B, T, D]\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-cased'\n",
    "model = MyModel.from_pretrained(\n",
    "    pretrained_model_name_or_path=BERT_MODEL_NAME, \n",
    "    config=config, \n",
    "    hidden_size_bert=HIDDEN_SIZE_BERT,\n",
    "    embed_size_word=EMBED_SIZE_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a456f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samer\\AppData\\Local\\Temp\\ipykernel_7656\\2397275565.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids.append(torch.tensor(encode['input_ids']))\n",
      "C:\\Users\\samer\\AppData\\Local\\Temp\\ipykernel_7656\\2397275565.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask.append(torch.tensor(encode['attention_mask']))\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, do_lower_case=True)\n",
    "\n",
    "#tk_jobs = []\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "jobs = df.job_title.tolist()\n",
    "for j in jobs:\n",
    "    encode = tokenizer.encode_plus(\n",
    "                        j,\n",
    "                        None,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length= 128,\n",
    "                        padding = 'max_length',\n",
    "                        return_token_type_ids= False,\n",
    "                        return_attention_mask= True,\n",
    "                        truncation=True,\n",
    "                        return_tensors = 'pt'      \n",
    "                                       )\n",
    "    \n",
    "    input_ids.append(torch.tensor(encode['input_ids']))\n",
    "    attention_mask.append(torch.tensor(encode['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd20c44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 12102,  5052,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15026292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(attention_mask[0]), type(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1df946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "tokens = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "input_ids_exp = tokenizer.build_inputs_with_special_tokens(tokens)\n",
    "\n",
    "# optional - discriminate sentence A or B.\n",
    "token_type_ids = tokenizer.create_token_type_ids_from_sequences(tokens)\n",
    "assert len(token_type_ids) == len(input_ids_exp), \"single sentence token tpye ids does not matched.\"\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "input_ids_exp = torch.tensor([input_ids_exp])\n",
    "token_type_ids_exp = torch.tensor([token_type_ids]) + 1 # becomes all 1\n",
    "# input_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60a5c901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1, 128]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0]*128]).shape, attention_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef11b8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f29e8118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_exp.shape#,\n",
    "input_ids[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f12e7cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1, 128]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0].shape , attention_mask[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2dd28401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "model.eval()\n",
    "embeddings = []\n",
    "ss1 = []\n",
    "for job in range(100):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = model(input_ids=input_ids[job]) #, attention_mask=attention_mask[job], token_type_ids=torch.tensor([[0]*128])\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "#        hidden_state = output[0]\n",
    "#        embeddings.append(embed)\n",
    "        ss1.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4ec69e42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'premuted_token_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [133]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m ss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m embeddings_array \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpremuted_token_embeddings\u001b[49m:    \n\u001b[0;32m      5\u001b[0m     sum_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(token[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     embeddings_array\u001b[38;5;241m.\u001b[39mappend(sum_vec)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'premuted_token_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "premuted_token_embeddings = ss[0].permute(1,0,2)\n",
    "\n",
    "embeddings_array = []\n",
    "for token in premuted_token_embeddings:    \n",
    "    sum_vec = torch.sum(token[-1:], dim=0)\n",
    "    embeddings_array.append(sum_vec)## embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec0c067c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 300)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(ss[0])\n",
    "arr.shape\n",
    "#arr = np.array([])\n",
    "for em in ss[1:]:\n",
    "    arr = np.vstack((arr,em))\n",
    "arr.shape\n",
    "arr = torch.tensor(arr).permute(1,0,2)\n",
    "\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "embed_words = []\n",
    "for embed in arr:\n",
    "    # option 1\n",
    "#     vec = torch.cat([x for x in embed[-4:]], dim=0)\n",
    "#     embed_words.append(vec)\n",
    "    # option 2\n",
    "    vec = torch.sum(embed[-4:], dim=0)\n",
    "    embed_words.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "05080bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100, 300])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6948f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_temp = []\n",
    "permuted = ss[0].permute(1,0,2)[1:]\n",
    "for token in ss[0]:    \n",
    "    sum_vec = torch.sum(token[-1:], dim=0)\n",
    "    v_temp.append(sum_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dd39962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss[0].shape\n",
    "permute_ = ss[0].permute(1,0,2)\n",
    "embeddings_array = []\n",
    "for token in permute_:    \n",
    "    sum_vec = torch.sum(token[-1:], dim=0)\n",
    "    embeddings_array.append(sum_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "87228992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[4]\n",
    "ss1[4].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71d5b7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0942, -0.7470, -0.4808, -1.1342, -0.3187,  0.5898, -1.1278, -0.5733,\n",
       "        -2.9823, -0.3715,  0.1594, -0.8888, -1.3297,  1.5315, -0.5492,  0.1243,\n",
       "        -0.6405, -0.8386, -0.1274, -0.3215,  0.8914, -0.0868, -1.1806,  1.9957,\n",
       "        -0.6228, -1.0396, -2.4755, -0.8926,  0.1639,  2.0686,  0.9769,  1.7476,\n",
       "        -1.9696,  0.0380, -0.3319,  1.1865, -2.0985, -2.3394, -1.1130, -0.4222,\n",
       "        -1.7908,  1.6347,  1.3268,  0.8771,  0.0572, -0.6786,  0.4012, -0.8841,\n",
       "         0.4252,  1.0750, -0.1496,  0.4367, -0.3810,  1.4738,  0.0243, -1.2522,\n",
       "        -1.4610,  0.6421, -0.0965, -0.7510, -2.0862, -0.0526, -1.8559,  2.9231,\n",
       "         2.2449, -0.0099, -1.4532, -1.4022, -1.4259,  1.4055, -1.7303, -0.0753,\n",
       "        -0.0910, -1.1743,  1.7392, -1.1135,  0.2755,  1.9611, -0.8392,  1.1992,\n",
       "         1.5793, -1.2127,  1.7677, -2.4366,  0.1138,  0.5713,  1.1973, -0.8328,\n",
       "         0.4585,  1.9672,  1.7817,  1.3759,  2.3485,  0.6467, -0.3440, -1.1367,\n",
       "         1.5754, -1.2732,  0.1950, -0.2704, -1.7814,  0.4592,  2.1050,  0.4631,\n",
       "        -1.2456, -0.6974,  1.5551,  0.1200, -0.4413,  0.3650,  1.4524, -2.0728,\n",
       "         2.3652,  0.3991,  0.7255,  0.3406,  1.9345,  0.2645, -3.3240, -0.8699,\n",
       "        -0.3199,  1.3360, -2.4730,  1.2795,  0.9957, -0.8295, -1.4034,  0.2857,\n",
       "        -0.5177,  0.3190,  1.2626,  0.0453,  1.5399, -1.9124,  2.0349,  1.9143,\n",
       "        -1.3585, -0.5090, -0.3105,  0.9191, -0.3320,  1.3007,  0.3579, -2.1121,\n",
       "         0.9572,  0.0255, -2.0037,  0.4685, -0.7717, -0.1906,  0.6374,  0.4432,\n",
       "         0.4951, -1.4795, -2.2362, -1.2107, -0.9459,  0.7994, -1.3317,  1.5666,\n",
       "         2.9376, -0.8607,  0.3391,  0.2985, -1.2114, -1.0923, -1.0940,  1.5845,\n",
       "         2.0059, -0.2602, -1.6833, -0.1023, -1.4403, -0.3133, -0.8405, -0.1977,\n",
       "         1.6467, -2.1759,  2.7296, -0.0264,  0.2917, -0.7400, -1.0797,  1.6222,\n",
       "        -0.3340,  2.2501,  0.4124, -0.5235, -0.1814,  0.0493,  1.4675,  1.1394,\n",
       "        -0.5664,  0.5136,  1.0997, -2.8590, -2.7557,  0.0133,  1.4976,  0.1527,\n",
       "         0.3085, -0.8353, -0.0053, -0.0557,  1.0459, -0.7541, -1.0493,  0.4643,\n",
       "         1.9846, -1.4151,  0.2287,  1.5860, -0.0798,  0.6414, -0.6359,  1.4774,\n",
       "        -0.5677, -0.9307, -1.0703,  1.1539,  2.4415, -2.6433, -1.2220, -1.1848,\n",
       "        -0.2807, -2.1741, -0.0040, -0.7811, -1.0837,  0.8250, -0.5180, -0.0171,\n",
       "        -0.2445, -1.9375,  0.3731, -0.0186, -1.3790,  0.2415, -1.2867,  0.6413,\n",
       "        -0.5460,  0.1723,  0.2136,  1.5325,  0.6220, -0.7570, -1.7677,  1.8905,\n",
       "         1.5245,  0.3543, -1.3415,  0.1140, -0.8993,  0.2725,  0.7813, -0.3290,\n",
       "         1.9566, -0.2035, -0.9529,  1.0346,  1.7142, -0.8018,  1.6213, -0.3241,\n",
       "        -0.6155, -0.5716,  1.7165, -0.2442, -0.1532, -0.7900, -1.1528,  1.2160,\n",
       "        -1.5508,  0.5568,  2.4376, -0.5358, -1.8453, -2.1315, -1.5049, -2.2101,\n",
       "         0.5031,  1.3045, -0.7452, -3.0119,  2.6210, -0.7423, -2.1484, -1.6134,\n",
       "        -1.3844, -1.8431, -1.5051, -1.9017,  0.3724,  0.5769, -1.8210, -1.7891,\n",
       "        -0.4626,  0.5534,  1.0845,  1.5514])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in text:\n",
    "    words = tokenizer.tokenize(text)\n",
    "    print(f\"tokenized text: {words}\")\n",
    "\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs[0]\n",
    "    premuted_token_embeddings = last_hidden_states.permute(1,0,2)\n",
    "\n",
    "    embeddings_array = []\n",
    "    for token in premuted_token_embeddings:    \n",
    "        sum_vec = torch.sum(token[-1:], dim=0)\n",
    "        embeddings_array.append(sum_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_text = [] \n",
    "with open(filename) as file:\n",
    "    for line in file:\n",
    "        list_of_text.append(line.rstrip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
